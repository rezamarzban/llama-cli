~/llama.cpp/build $ cmake .. \
  -G Ninja \
  -DCMAKE_BUILD_TYPE=Release \
  -DBUILD_SHARED_LIBS=OFF \
  -DGGML_MTMD=OFF \
  -DGGML_OPENCL=ON \
  -DGGML_OPENCL_EMBED_KERNELS=ON \
  -DGGML_OPENCL_USE_ADRENO_KERNELS=ON \
  -DLLAMA_BUILD_SERVER=OFF \
  -DLLAMA_BUILD_TESTS=OFF \
  -DCMAKE_C_COMPILER=clang \
  -DCMAKE_CXX_COMPILER=clang++
-- The C compiler identification is Clang 21.1.8
-- The CXX compiler identification is Clang 21.1.8
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /data/data/com.termux/files/usr/bin/clang - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /data/data/com.termux/files/usr/bin/clang++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
CMAKE_BUILD_TYPE=Release
-- Found Git: /data/data/com.termux/files/usr/bin/git (found version "2.52.0")
-- The ASM compiler identification is Clang with GNU-like command-line
-- Found assembler: /data/data/com.termux/files/usr/bin/clang
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Check if compiler accepts -pthread
-- Check if compiler accepts -pthread - yes
-- Found Threads: TRUE
-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF
-- CMAKE_SYSTEM_PROCESSOR: aarch64
-- GGML_SYSTEM_ARCH: ARM
-- Including CPU backend
-- Found OpenMP_C: -fopenmp=libomp (found version "5.1")
-- Found OpenMP_CXX: -fopenmp=libomp (found version "5.1")
-- Found OpenMP: TRUE (found version "5.1")
-- ARM detected
-- Performing Test GGML_COMPILER_SUPPORTS_FP16_FORMAT_I3E
-- Performing Test GGML_COMPILER_SUPPORTS_FP16_FORMAT_I3E - Failed
CMake Warning at ggml/src/ggml-cpu/CMakeLists.txt:141 (message):
  ARM -march/-mcpu not found, -mcpu=native will be used
Call Stack (most recent call first):
  ggml/src/CMakeLists.txt:445 (ggml_add_cpu_backend_variant_impl)


-- Performing Test GGML_MACHINE_SUPPORTS_dotprod
-- Performing Test GGML_MACHINE_SUPPORTS_dotprod - Success
-- Performing Test GGML_MACHINE_SUPPORTS_i8mm
-- Performing Test GGML_MACHINE_SUPPORTS_i8mm - Failed
-- Performing Test GGML_MACHINE_SUPPORTS_noi8mm
-- Performing Test GGML_MACHINE_SUPPORTS_noi8mm - Success
-- Performing Test GGML_MACHINE_SUPPORTS_sve
-- Performing Test GGML_MACHINE_SUPPORTS_sve - Failed
-- Performing Test GGML_MACHINE_SUPPORTS_nosve
-- Performing Test GGML_MACHINE_SUPPORTS_nosve - Success
-- Performing Test GGML_MACHINE_SUPPORTS_sme
-- Performing Test GGML_MACHINE_SUPPORTS_sme - Failed
-- Performing Test GGML_MACHINE_SUPPORTS_nosme
-- Performing Test GGML_MACHINE_SUPPORTS_nosme - Success
-- Checking for ARM features using flags:
--   -U__ARM_FEATURE_MATMUL_INT8
--   -U__ARM_FEATURE_SVE
--   -U__ARM_FEATURE_SME
--   -mcpu=native+dotprod+noi8mm+nosve+nosme
-- Performing Test HAVE_DOTPROD
-- Performing Test HAVE_DOTPROD - Success
-- Performing Test HAVE_SVE
-- Performing Test HAVE_SVE - Failed
-- Performing Test HAVE_MATMUL_INT8
-- Performing Test HAVE_MATMUL_INT8 - Failed
-- Performing Test HAVE_FMA
-- Performing Test HAVE_FMA - Success
-- Performing Test HAVE_FP16_VECTOR_ARITHMETIC
-- Performing Test HAVE_FP16_VECTOR_ARITHMETIC - Success
-- Performing Test HAVE_SME
-- Performing Test HAVE_SME - Failed
-- Adding CPU backend variant ggml-cpu: -U__ARM_FEATURE_MATMUL_INT8;-U__ARM_FEATURE_SVE;-U__ARM_FEATURE_SME;-mcpu=native+dotprod+noi8mm+nosve+nosme
-- Looking for include file OpenCL/cl.h
-- Looking for include file OpenCL/cl.h - not found
-- Looking for CL_VERSION_3_0
-- Looking for CL_VERSION_3_0 - found
-- Found OpenCL: /data/data/com.termux/files/usr/lib/libOpenCL.so (found version "3.0")
-- Found Python3: /data/data/com.termux/files/usr/bin/python3.12 (found version "3.12.12") found components: Interpreter
-- OpenCL will use matmul kernels optimized for Adreno
-- opencl: embedding kernel add
-- opencl: embedding kernel add_id
-- opencl: embedding kernel argsort
-- opencl: embedding kernel tri
-- opencl: embedding kernel fill
-- opencl: embedding kernel clamp
-- opencl: embedding kernel cpy
-- opencl: embedding kernel cvt
-- opencl: embedding kernel diag_mask_inf
-- opencl: embedding kernel div
-- opencl: embedding kernel gelu
-- opencl: embedding kernel gemv_noshuffle_general
-- opencl: embedding kernel gemv_noshuffle
-- opencl: embedding kernel get_rows
-- opencl: embedding kernel glu
-- opencl: embedding kernel group_norm
-- opencl: embedding kernel solve_tri
-- opencl: embedding kernel im2col_f32
-- opencl: embedding kernel im2col_f16
-- opencl: embedding kernel mean
-- opencl: embedding kernel mul_mat_Ab_Bi_8x4
-- opencl: embedding kernel mul_mv_f16_f16
-- opencl: embedding kernel mul_mv_f16_f32_1row
-- opencl: embedding kernel mul_mv_f16_f32_l4
-- opencl: embedding kernel mul_mv_f16_f32
-- opencl: embedding kernel mul_mv_f32_f32
-- opencl: embedding kernel mul_mv_q4_0_f32
-- opencl: embedding kernel mul_mv_q4_0_f32_v
-- opencl: embedding kernel mul_mv_q4_0_f32_8x_flat
-- opencl: embedding kernel mul_mv_q4_0_f32_1d_8x_flat
-- opencl: embedding kernel mul_mv_q4_0_f32_1d_16x_flat
-- opencl: embedding kernel mul_mv_q4_k_f32
-- opencl: embedding kernel mul_mv_q6_k_f32
-- opencl: embedding kernel mul_mv_q6_k_f32_flat
-- opencl: embedding kernel mul_mv_q8_0_f32
-- opencl: embedding kernel mul_mv_q8_0_f32_flat
-- opencl: embedding kernel mul_mv_mxfp4_f32
-- opencl: embedding kernel mul_mv_mxfp4_f32_flat
-- opencl: embedding kernel mul_mv_id_q4_0_f32_8x_flat
-- opencl: embedding kernel mul_mv_id_q8_0_f32
-- opencl: embedding kernel mul_mv_id_q8_0_f32_flat
-- opencl: embedding kernel mul_mv_id_mxfp4_f32
-- opencl: embedding kernel mul_mv_id_mxfp4_f32_flat
-- opencl: embedding kernel gemm_moe_mxfp4_f32
-- opencl: embedding kernel gemv_moe_mxfp4_f32
-- opencl: embedding kernel mul_mm_f32_f32_l4_lm
-- opencl: embedding kernel mul_mm_f16_f32_l4_lm
-- opencl: embedding kernel mul_mm_q8_0_f32_l4_lm
-- opencl: embedding kernel mul_mm_q6_k_f32_l4_lm
-- opencl: embedding kernel mul_mm_q8_0_f32_8x4
-- opencl: embedding kernel gemv_noshuffle_general_q8_0_f32
-- opencl: embedding kernel mul
-- opencl: embedding kernel norm
-- opencl: embedding kernel relu
-- opencl: embedding kernel rms_norm
-- opencl: embedding kernel rope
-- opencl: embedding kernel scale
-- opencl: embedding kernel set_rows
-- opencl: embedding kernel sigmoid
-- opencl: embedding kernel silu
-- opencl: embedding kernel softmax_4_f32
-- opencl: embedding kernel softmax_4_f16
-- opencl: embedding kernel softmax_f32
-- opencl: embedding kernel softmax_f16
-- opencl: embedding kernel sqr
-- opencl: embedding kernel sqrt
-- opencl: embedding kernel ssm_conv
-- opencl: embedding kernel sub
-- opencl: embedding kernel sum_rows
-- opencl: embedding kernel transpose
-- opencl: embedding kernel concat
-- opencl: embedding kernel tsembd
-- opencl: embedding kernel upscale
-- opencl: embedding kernel tanh
-- opencl: embedding kernel expm1
-- opencl: embedding kernel softplus
-- opencl: embedding kernel pad
-- opencl: embedding kernel repeat
-- opencl: embedding kernel mul_mat_f16_f32
-- opencl: embedding kernel mul_mm_f16_f32_kq_kqv
-- opencl: embedding kernel conv2d
-- opencl: embedding kernel conv2d_f16_f32
-- opencl: embedding kernel flash_attn_f32_f16
-- opencl: embedding kernel flash_attn_f16
-- opencl: embedding kernel flash_attn_f32
-- Including OpenCL backend
-- ggml version: 0.9.5
-- ggml commit:  4d688f9eb
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found OpenSSL: /data/data/com.termux/files/usr/lib/libcrypto.so (found version "3.4.1")
-- Performing Test OPENSSL_VERSION_SUPPORTED
-- Performing Test OPENSSL_VERSION_SUPPORTED - Success
-- OpenSSL found: 3.4.1
-- Generating embedded license file for target: common
-- Configuring done (19.1s)
-- Generating done (0.3s)
-- Build files have been written to: /data/data/com.termux/files/home/llama.cpp/build
